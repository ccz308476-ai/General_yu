'''
本文件由BiliBili：魔傀面具整理   
论文链接：https://arxiv.org/pdf/2402.13616
'''   
     
import os, sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)) + '/../../../..') 
 
import warnings     
warnings.filterwarnings('ignore')     
from calflops import calculate_flops 
   
import torch 
import torch.nn as nn 

from engine.extre_module.ultralytics_nn.conv import Conv, autopad  
     
class ADown(nn.Module):
    def __init__(self, c1, c2):  # ch_in, ch_out, shortcut, kernels, groups, expand  
        super().__init__()    
        self.c = c2 // 2
        self.cv1 = Conv(c1 // 2, self.c, 3, 2, 1)     
        self.cv2 = Conv(c1 // 2, self.c, 1, 1, 0)   
  
    def forward(self, x): 
        x = torch.nn.functional.avg_pool2d(x, 2, 1, 0, False, True)     
        x1,x2 = x.chunk(2, 1)  
        x1 = self.cv1(x1)
        x2 = torch.nn.functional.max_pool2d(x2, 3, 2, 1)    
        x2 = self.cv2(x2)
        return torch.cat((x1, x2), 1)    
    
if __name__ == '__main__':
    RED, GREEN, BLUE, YELLOW, ORANGE, RESET = "\033[91m", "\033[92m", "\033[94m", "\033[93m", "\033[38;5;208m", "\033[0m"  
    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
    batch_size, in_channel, out_channel, height, width = 1, 16, 32, 32, 32
    inputs = torch.randn((batch_size, in_channel, height, width)).to(device)
    
    module = ADown(in_channel, out_channel).to(device)  
     
    outputs = module(inputs) 
    print(GREEN + f'inputs.size:{inputs.size()} outputs.size:{outputs.size()}' + RESET)

    print(ORANGE) 
    flops, macs, _ = calculate_flops(model=module,
                                     input_shape=(batch_size, in_channel, height, width),   
                                     output_as_string=True,  
                                     output_precision=4,
                                     print_detailed=True)
    print(RESET)